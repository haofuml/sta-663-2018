{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab11B: Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Background**\n",
    "\n",
    "You will use Spark and Python to process genomic data. This consists of bout 3 billion nucleotides in the human genome and a smaller number for the flatworm C. elegans. The genome sequences are found as FASTA files. For the purposes of this exercise, treat lower and upper case as the same. Recall that FASTA files have comment lines starting with '>' that must be excluded from the analysis. For the exercises below, assume that k=20 for the k-mers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>341</td><td>application_1522938745830_0496</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://vcm-2168.oit.duke.edu:8088/proxy/application_1522938745830_0496/\">Link</a></td><td><a target=\"_blank\" href=\"http://vcm-2175.oit.duke.edu:8042/node/containerlogs/container_e19_1522938745830_0496_01_000001/user06037\">Link</a></td><td>âœ”</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "%%spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hdfs://vcm-2167.oit.duke.edu:8020/data/c_elegans/Caenorhabditis_elegans.WBcel235.dna.chromosome.I.fa\n",
      "hdfs://vcm-2167.oit.duke.edu:8020/data/c_elegans/Caenorhabditis_elegans.WBcel235.dna.chromosome.II.fa\n",
      "hdfs://vcm-2167.oit.duke.edu:8020/data/c_elegans/Caenorhabditis_elegans.WBcel235.dna.chromosome.III.fa\n",
      "hdfs://vcm-2167.oit.duke.edu:8020/data/c_elegans/Caenorhabditis_elegans.WBcel235.dna.chromosome.IV.fa\n",
      "hdfs://vcm-2167.oit.duke.edu:8020/data/c_elegans/Caenorhabditis_elegans.WBcel235.dna.chromosome.V.fa\n",
      "hdfs://vcm-2167.oit.duke.edu:8020/data/c_elegans/Caenorhabditis_elegans.WBcel235.dna.chromosome.X.fa"
     ]
    }
   ],
   "source": [
    "hadoop = sc._jvm.org.apache.hadoop\n",
    "\n",
    "fs = hadoop.fs.FileSystem\n",
    "conf = hadoop.conf.Configuration() \n",
    "path = hadoop.fs.Path('/data/c_elegans')\n",
    "\n",
    "for f in fs.get(conf).listStatus(path):\n",
    "    print f.getPath()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Exercise 2 (50 points)**\n",
    "\n",
    "Write a program using `spark` to find 5 most common k-mers (shifting windows of length k) in the human genome. Ignore case when processing k-mers. You can work one line at a time - we will ignore k-mers that wrap around lines. You should write a function that takes a path to FASTA files and a value for k, and returns an key-value RDD of k-mer counts. Remember to strip comment lines that begin with '>' from the anlaysis. \n",
    "\n",
    "Use k=20\n",
    "\n",
    "**Note**: The textFile method takes an optional second argument for controlling the number of partitions of the file. By default, Spark creates one partition for each block of the file (blocks being 128MB by default in HDFS), but you can also ask for a higher number of partitions by passing a larger value. Please set this paramter to 60 - it will speed up processing.\n",
    "\n",
    "**Check**: Use the C. elegans genome at `/data/c_elegans`. You should get \n",
    "\n",
    "```\n",
    "[\n",
    "(u'ATATATATATATATATATAT', 2217), \n",
    "(u'TATATATATATATATATATA', 2184), \n",
    "(u'CTCTCTCTCTCTCTCTCTCT', 1373), \n",
    "(u'TCTCTCTCTCTCTCTCTCTC', 1361), \n",
    "(u'AGAGAGAGAGAGAGAGAGAG', 1033)\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_mers(g_string, k):\n",
    "    tmp = [g_string[i:] for i in range(k)]\n",
    "    return map(lambda x: (''.join(x),1), zip(*tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_mers_all(path, k):\n",
    "    rdd = sc.textFile(path,60).filter(lambda x: x[0]!='>')\n",
    "    rdd = rdd.flatMap(lambda g_string: k_mers(g_string, k))\n",
    "    return rdd.reduceByKey(lambda x, y: x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "path_pattern = '/data/c_elegans/Caenorhabditis_elegans.WBcel235.dna.chromosome.%s.fa'\n",
    "name_list = ['I','II','III','IV','V']\n",
    "rdd_list = [k_mers_all(path_pattern%name, 20) for name in name_list]\n",
    "df_list = [spark.createDataFrame(rdd,['sequence','count%i'%i]) for i,rdd in enumerate(rdd_list)]\n",
    "df = reduce(lambda x,y: x.join(y, on='sequence', how='outer'), df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+------+------+------+------+\n",
      "|            sequence|count0|count1|count2|count3|count4|\n",
      "+--------------------+------+------+------+------+------+\n",
      "|AAAAAAAAAAAAAAATATTT|     1|  null|     1|  null|  null|\n",
      "|AAAAAAAAAAAAACAAACCG|     1|  null|  null|  null|  null|\n",
      "|AAAAAAAAAAAAAGTCAACT|  null|  null|  null|     1|  null|\n",
      "|AAAAAAAAAAAACGTCTAAA|  null|     1|  null|  null|  null|\n",
      "|AAAAAAAAAAAACTCAATTA|  null|     1|  null|  null|  null|\n",
      "+--------------------+------+------+------+------+------+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+------+------+------+------+\n",
      "|            sequence|count0|count1|count2|count3|count4|\n",
      "+--------------------+------+------+------+------+------+\n",
      "|AAAAAAAAAAAAAAATATTT|     1|     0|     1|     0|     0|\n",
      "|AAAAAAAAAAAAACAAACCG|     1|     0|     0|     0|     0|\n",
      "|AAAAAAAAAAAAAGTCAACT|     0|     0|     0|     1|     0|\n",
      "|AAAAAAAAAAAACGTCTAAA|     0|     1|     0|     0|     0|\n",
      "|AAAAAAAAAAAACTCAATTA|     0|     1|     0|     0|     0|\n",
      "+--------------------+------+------+------+------+------+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+------+------+------+------+-----+\n",
      "|            sequence|count0|count1|count2|count3|count4|count|\n",
      "+--------------------+------+------+------+------+------+-----+\n",
      "|AAAAAAAAAAAAAAATATTT|     1|     0|     1|     0|     0|    2|\n",
      "|AAAAAAAAAAAAACAAACCG|     1|     0|     0|     0|     0|    1|\n",
      "|AAAAAAAAAAAAAGTCAACT|     0|     0|     0|     1|     0|    1|\n",
      "|AAAAAAAAAAAACGTCTAAA|     0|     1|     0|     0|     0|    1|\n",
      "|AAAAAAAAAAAACTCAATTA|     0|     1|     0|     0|     0|    1|\n",
      "+--------------------+------+------+------+------+------+-----+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "df = df.withColumn('count', df['count0']+df['count1']+df['count2']+df['count3']+df['count4'])\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            sequence|count|\n",
      "+--------------------+-----+\n",
      "|ATATATATATATATATATAT| 1757|\n",
      "|TATATATATATATATATATA| 1739|\n",
      "|CTCTCTCTCTCTCTCTCTCT|  990|\n",
      "|TCTCTCTCTCTCTCTCTCTC|  976|\n",
      "|AGAGAGAGAGAGAGAGAGAG|  861|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "sorted_df = df.select(['sequence','count']).sort(df['count'].desc())\n",
    "sorted_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3 (10 points)** \n",
    "\n",
    "As a simple QC measure, we can assume that the k-mers that have a count of only 1 are due to sequencing errors. Put all the k-mers with a count of 2 or more in a Spark DataFrame with two columns (sequence, count). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            sequence|count|\n",
      "+--------------------+-----+\n",
      "|ATATATATATATATATATAT| 1757|\n",
      "|TATATATATATATATATATA| 1739|\n",
      "|CTCTCTCTCTCTCTCTCTCT|  990|\n",
      "|TCTCTCTCTCTCTCTCTCTC|  976|\n",
      "|AGAGAGAGAGAGAGAGAGAG|  861|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "valid_df = sorted_df.filter(sorted_df['count'] > 1)\n",
    "valid_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4 (10 points)**\n",
    "\n",
    "Find all k-mers with count greater than 1 that are palindromes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "@F.udf\n",
    "def reverse_seq(seq):\n",
    "    return seq[::-1]\n",
    "palindromes = valid_df.withColumn('reverse_seq',reverse_seq(valid_df['sequence']))\n",
    "palindromes = palindromes.filter(palindromes['sequence'] == palindromes['reverse_seq'])\n",
    "palindromes = palindromes.select(['sequence','count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            sequence|count|\n",
      "+--------------------+-----+\n",
      "|TTTTTTTTTTTTTTTTTTTT|  185|\n",
      "|AAAAAAAAAAAAAAAAAAAA|  135|\n",
      "|GGGGGGGGGGGGGGGGGGGG|  135|\n",
      "|CCCCCCCCCCCCCCCCCCCC|  111|\n",
      "|AATAATAATAATAATAATAA|   71|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "palindromes.show(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
